#!/usr/local/bin/python3

###Was modifed for Aspragus *cluster.boundary.without.PARE.validation.list file files, they had 'chr' in front of chromosme number so that is removed and chrid variable is made - See brachy folder for original version. This version might
### work well without any error in future, though I didn't tested if no 'chr' is present will replace give an error

###Description:
### Goes through different file formats generated by Pingchuans script to merge and report
### non-redundant set of phased loci. Also uniq phased loci from each library.
###Contact: atulkakrana@gmail.com

import os,glob,sys,difflib,time,shutil

########### USER SETTINGS ########

res_folder = '24ALL'
p_val = '1e-07' ### If specified a poor cutoff - it will include variants of loci with good cut-off
genome = ' PINEAPPLE_UIUC3'##Name for PHAS cluster naming
fileType = 'L' ## L = *cluster.boundary.without.PARE.validation.list file, N = *NO.by.PARE.file, Y = *YES.by.PARE.file, if formatted CSV for intercomparision
region = 'I' ## 'G': Genic and 'I': Intergenic - This affects overlap ration in main()
##################################

def RemoveRedundant(res_folder,p_val,fileType):
    """
    Remove redundant entries by checking those in the pool
    """
    fh_out = open('PHASRedundant.log','w')
    ##Read files
    if fileType == 'Y':
        fls = glob.glob(r'./%s/*.YES.by.PARE.txt' % (res_folder))
    elif fileType == 'N':
        fls = glob.glob(r'./%s/*.YES.by.PARE.txt' % (res_folder))
    else:
        fls = glob.glob(r'./%s/*converted.list' % (res_folder))
        
    #print (fls,'\n')
    #print ('Total files passed for redundancy removal: %s' % (len(fls)))
    
    main_dict = {} ## declare empty dictionary
    anum = 1 ## To name PHAS loci
    for afile in fls: ###
        print ('**\nAnalyzing file: %s\n' % (afile))
        tmp_dict = {}## Dictionary to store values for one file - recycled after every file
        tmp_list = [] ## List to hol dall co-odinates before making a dictionary based on chromosme
        neg_list = []## List to store keys that needs to be removed
        fh_in = open(afile, 'r')
        alib = afile.split('/')[-1].split('.')[0]###
        print ("File:",afile,"lib:",alib)
        
        shutil.rmtree('./temp',ignore_errors=True)
        os.mkdir('./temp')
        outfile = './temp/PHAS_Uniq_%s' % (afile.split('/')[-1]) ### File to record unique entries of every library
        fh_out2 = open(outfile,'w')
        
        ###First Instance - Fill up the dictionary with entries from first file
        if not main_dict.values(): ## First file will populate dictionary
            lines = [i for i in fh_in if i[:-1]] ## Remove empty lines one liner and read all with content
            for ent in lines:
                # print(ent.strip('\n'))
                ent_splt = ent.strip('\n').split('\t')
                if float(ent_splt[1]) == float(p_val): ### Equals p-value cut-off specifed above
                    #print('Adding')
                    #print(ent_splt[2],chrid.replace('chr',''))
                    #print('making key')
                    key = '%s-%s-%s' % (ent_splt[2],ent_splt[3],ent_splt[4])###Chrid, start and end makes a key
                    print(key)
                    #print('Key made')
                    
                    chrid = ent_splt[2]
                    start = int(ent_splt[3])
                    end = int(ent_splt[4]) ## 1 added because when opening a range using start and end, end number is not included in range - - Critical bug fixed in v4->v5 and later regressed/removed in v9->v10
        
                    #val_start = chrid +str(start)
                    #val_end = chrid+str(end)
                    #print ('calculating value')
                    #value  = (list(range(int(val_start),int(val_end))),ent_splt,alib) ### The range has chromosme number in begining to make range unique to chromosme
                    
                    value = ((chrid,start,end),ent_splt,alib)
                    
                    #print ('Key:%s and Val%s' % (key,value))
                    #print('Done\n')
                    ###Check for redundancy, if above cutoff add to dict and write ent  to file
                    tmp_dict[key] = value
                    
                #    
                #else:
                #    #print ('***All entries with specified cutoff analyzed for - %s' % (afile))
                #    #break
                #    pass
            main_dict.update(tmp_dict) ## Update the main dict

        ##Second and further Instance - Match the entries of new file with dictioary and add new one#############
        else: ##Dictionary has key and value populated from first file and now remove redundancy
            lines = [i for i in fh_in if i[:-1]] ## Remove empty lines one liner
            for ent in lines:
                ratiodict= {}###dict to hold ratios of comaprarision of this entry with all in dictionary
                ent_splt = ent.strip('\n').split('\t')
                # print('\nEntry: %s:' % (ent.strip('\n')))
                #print('\nCurrent entry:',ent_splt)
    
                ###Compare with dict entries and get ratio
                if float(ent_splt[1]) == float(p_val): ### Equals p-value cut-off specifed above
                    #print('Adding')
                    start = int(ent_splt[3])
                    end = int(ent_splt[4])### 1 added because when oening a range using start and end, end number is not included in range - Critical bug fixed in v4->v5 and later regressed/removed in v9->v10
                    chrid = ent_splt[2]
                    #print ('calculating value')
                    #value  = (list(range(int(chrid+str(start)),int(chrid+str(end)))),ent_splt,alib) ##@@@@@@@@
                    value = ((chrid,start,end),ent_splt,alib) 
                    newRegion = list(range(start,end))
                    
                    #print('matching')
                    for i in main_dict.values():##Compare with all dictionary values
                        #print(i)
                        if chrid == i[0][0]:
                            #print (i, main_dict[i])
                            existRegion = list(range(i[0][1],i[0][2]))
                            #print (existRegion,newRegion)
                            sm=difflib.SequenceMatcher(None,existRegion,newRegion)
                            ratiodict[str(i)]=round(sm.ratio(),2) ### Make a dict of main dict entries and their comparision ratio with current new entry
                            #ratiolist.append(round(sm.ratio(),2))
                        #elif chrid > i[0][0]:
                        ##    continue
                        else:
                            ratiodict[str(i)]=round(0.00,2) ## None of the existing entry matches with the current ones
                            pass
                else:
                    #print('Passed')
                    continue
                
                # Decide if entry is different enough to be added - Get the entry with max match to one being tested and make its key again
                mainkey = max(ratiodict,key=ratiodict.get)### Key from main_dict with max comparable ratio for current entry
                print ('mainkey',mainkey,'Mainkey decode',mainkey.split('[')[0].split("(")[2].split(")")[0].replace(" ","").split(","),"\n")
                mainkey_decode = mainkey.split('[')[0].split("(")[2].split(")")[0].replace(" ","").split(",")
                mainkey_remade  = '%s-%s-%s' % (mainkey_decode[0].replace("'",""),mainkey_decode[1],mainkey_decode[2])
                # print('Mainkey:',mainkey,'mainkey2:',mainkey_remade)
                # sys.exit()
                               
                
                maxratio = ratiodict[mainkey] ### Max ratio
                #print(mainkey_remade,maxratio)### If maxratio is zero same entry will appear again here
                #print (ent,maxratio)
                
                ## Key for current entry is made only if there is some match in region
                key = '%s-%s-%s' % (ent_splt[2],ent_splt[3],ent_splt[4])
                
                if maxratio <= overlapCutoff: ### Overlap is less then cutoff then treat as new loci and no need to delete any entry from existing values
                    #print ('Adding new key')
                    #key = '%s-%s-%s' % (ent_splt[2],ent_splt[3],ent_splt[4])
                    tmp_dict[key]=value ## Life = one file
                    fh_out2.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (value[1][0],value[1][1],value[1][2],value[1][3],value[1][4],value[1][5],value[1][6]))### Entries unique to each library - library name included in file name
    
                    
                elif maxratio > overlapCutoff: #### Choose the longest loci
                    print('Selecting longest loci')
                    print('Remade',mainkey_remade, 'New Key',key,)
                    print ('Length of existing:%s | Length of new:%s' % ((int(mainkey_decode[2])-int(mainkey_decode[1])+1),(int(value[0][2])-int(value[0][1])+1) ))
                    if (int(mainkey_decode[2])-int(mainkey_decode[1])+1) < (int(value[0][2])-int(value[0][1])+1):### New Loci is longer ------------------------>>>>>>>>>>>>>>>>>. Check
                        print ('New phased loci is longer')
                        neg_list.append(mainkey_remade)
                        tmp_dict[key]=value
                    
                    else: ## The loci in dictionary is longer
                        print('Existing phased loci is longer or equal to new')
                        pass
                else:

                    print('Redundant')
                    pass
                
            main_dict.update(tmp_dict) ### Update the main dict
            
            ########################Test####################
            ##print ('Dictionary')
            #fh_test = open('keysTest','w')
            #for i in main_dict.keys():
            #    #print (i)
            #    fh_test.write('%s\n' % i)
            #print ('\nLength of dictionary: %s' % (len(main_dict)))
            #
            #
            #fh_test2 = open('NegKeytest', 'w')
            #for i in neg_list:
            #    fh_test2.write('%s\n' % i)
            #print ('Length of negative list: %s' % (len(neg_list)))
            ################################################
            
            for akey in neg_list:
                print (akey)
                try:
                    del main_dict[akey]
                    print (akey, 'Key found in main dict and is being removed')
                except KeyError:
                    print (akey, '\nKey not found')
                    pass
                
            pass
        print ('\n**Number of Phased loci after %s lib: %s**\n' % (alib,len(main_dict)))
        fh_out.write('**Number of Phased loci %s lib: %s**\n' % (alib,len(main_dict)))
        fh_out2.close()
    
    print ('Number of final phased loci: %s' % (len(main_dict)))
    fh_out.write('Number of final phased loci: %s' % (len(main_dict)))
    fh_out.close()
    return main_dict

def compare(res_folder,fileType):
    """
    compare two csv results files generated from script - Format should be same for both files 
    """
    fh_out = open('PHASRedundant.log','w')
    fls = glob.glob(r'./%s/*converted.list' % (res_folder))
    
    main_dict = {} ## declare empty dictionary
    anum = 1 ## To name PHAS loci
    
    for afile in fls: ###
        print ('**\nAnalyzing file: %s\n' % (afile))
        tmp_dict = {}## Dictionary to store values for one file - recycled after every file
        tmp_list = [] ## List to hol dall co-odinates before making a dictionary based on chromosme
        neg_list = []## List to store keys that needs to be removed
        fh_in = open(afile, 'r')
        alib = afile.split('/')[-1].split('.')[0]###
        print ("File:",afile,"lib:",alib)
        
        outfile = 'PHAS_Uniq_%s' % (afile.split('/')[-1]) ### File to record unique entries of every library
        fh_out2 = open(outfile,'w')
        
        ###First Instance - Fill up the dictionary with entries from first file
        if not main_dict.values(): ## First file will populate dictionary
            lines = [i for i in fh_in if i[:-1]] ## Remove empty lines one liner and read all with content
            for ent in lines:
                print(ent.strip('\n'))
                ent_splt = ent.strip('\n').split('\t')
                #if float(ent_splt[1]) == float(p_val): ### Equals p-value cut-off specifed above
                key = '%s-%s-%s' % (ent_splt[2],ent_splt[3],ent_splt[4])###Chr id, start and end makes a key
                
                chrid = int(ent_splt[2])
                start = int(ent_splt[3])
                end = int(ent_splt[4]) ## 1 added because when opening a range using start and end, end number is not included in range - - Critical bug fixed in v4->v5 and later regressed/removed in v9->v10
                value = ((chrid,start,end),ent_splt,alib)
                tmp_dict[key] = value
                print('Value:',value)
            main_dict.update(tmp_dict) ## Update the main dict

        ##Second and further Instance - Match the entries of new file with dictioary and add new one#############
        else: ## Dictionary has keys and value spopulated from first file and now remove redundancy
            lines = [i for i in fh_in if i[:-1]] ## Remove empty lines one liner
            for ent in lines:
                ratiodict= {}###dict to hold ratios of comaprarision of this entry with all in dictionary
                ent_splt = ent.strip('\n').split('\t')
                print('\nEntry: %s:' % (ent.strip('\n')))
                #print('\nCurrent entry:',ent_splt)
    
                ###Compare with dict entries and get ratio
                start = int(ent_splt[3])
                end = int(ent_splt[4])### 1 added because when oening a range using start and end, end number is not included in range - Critical bug fixed in v4->v5 and later regressed/removed in v9->v10
                chrid = int(ent_splt[2])
                value = ((chrid,start,end),ent_splt,alib)
                print('Value:',value)
                newRegion = list(range(start,end))
                
                #print('matching')
                for i in main_dict.values():##Compare with all dictionary values
                    #print(i)
                    if chrid == i[0][0]:
                        #print (i, main_dict[i])
                        existRegion = list(range(i[0][1],i[0][2]))
                        #print (existRegion,newRegion)
                        sm=difflib.SequenceMatcher(None,existRegion,newRegion)
                        ratiodict[str(i)]=round(sm.ratio(),2)### Make a dict of main dict entries and their comparision ratio with current new entry
                    else:
                        ratiodict[str(i)]=round(0.00,2) ## None of the existing entry matches with the current ones
                        pass

                # Decide if entry is different enough to be added - Get the entry with max match to one being tested and make its key again
                mainkey = max(ratiodict,key=ratiodict.get)### Key from main_dict with max comparable ratio for current entry
                #print ('mainkey',mainkey,'Mainkey decode',mainkey.split('[')[0].split("(")[2].split(")")[0].replace(" ","").split(","))
                mainkey_decode = mainkey.split('[')[0].split("(")[2].split(")")[0].replace(" ","").split(",")
                mainkey_remade  = '%s-%s-%s' % (mainkey_decode[0].replace("'",""),mainkey_decode[1],mainkey_decode[2])
                maxratio = ratiodict[mainkey]### Max ratio
                
                ## Key for current entry is made only if there is some match in region
                key = '%s-%s-%s' % (ent_splt[2],ent_splt[3],ent_splt[4])
                if maxratio <= 0.25: ### Treat as new loci and no need to delete any entry from existing values
                    tmp_dict[key]=value ## Life = one file
                    fh_out2.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (value[1][0],value[1][1],value[1][2],value[1][3],value[1][4],value[1][5],value[1][6]))### Entries unique to each library - library name included in file name
    
                #elif maxratio > 0.25: #### Choose the longest loci
                #    print('Selecting longest loci')
                #    print('Remade',mainkey_remade, 'New Key',key,)
                #    print ('Length of existing:%s | Length of new:%s' % ((int(mainkey_decode[2])-int(mainkey_decode[1])+1),(int(value[0][2])-int(value[0][1])+1) ))
                #    if (int(mainkey_decode[2])-int(mainkey_decode[1])+1) < (int(value[0][2])-int(value[0][1])+1):### New Loci is longer ------------------------>>>>>>>>>>>>>>>>>. Check
                #        print ('New phased loci is longer')
                #        neg_list.append(mainkey_remade)
                #        tmp_dict[key]=value
                #    
                #    else: ## The loci in dictionary is longer
                #        print('Existing phased loci is longer or equal to new')
                #        pass
                
                else:
                    print('Redundant')
                    pass
                
            main_dict.update(tmp_dict) ### Update the main dict           
            for akey in neg_list:
                print (akey)
                try:
                    del main_dict[akey]
                    print (akey, 'Key found in main dict and is being removed')
                except KeyError:
                    print (akey, '\nKey not found')
                    pass
                
            pass
        print ('\n**Number of Phased loci after %s lib: %s**\n' % (alib,len(main_dict)))
        fh_out.write('**Number of Phased loci %s lib: %s**\n' % (alib,len(main_dict)))
        fh_out2.close()
    
    print ('Number of final phased loci: %s' % (len(main_dict)))
    fh_out.write('Number of final phased loci: %s' % (len(main_dict)))
    fh_out.close()
    return main_dict

def writer(main_dict):
    print ('Writing Results')
    outfile1 = 'Final_PHAS_Loci_%s_%s.csv' % (p_val,res_folder)
    fh_out1 = open(outfile1,'w')

    outfile2 = 'Final_PHASLociID_%s_%s' % (p_val,res_folder)
    fh_out2 = open(outfile2,'w')### For our Genome viewer, No header required
    outfile3 = 'Final_PHASLociID_%s_%s.ping' % (p_val,res_folder)
    fh_out3 = open(outfile3,'w')
    
    if fileType == 'C':
        fh_out1.write('Name\tp-val\tChr\tStart\tEnd\tStrand\tLib\tfileName\n')
        for value in main_dict.values():
            print(value)
            #print('Phas-%s\t%s\t%s\t%s\t%s\t%s\n' % (anum,value[1][1],value[1][2],value[1][3],value[1][4],value[1][6]))
            fh_out1.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (value[1][0],value[1][1],value[1][2],value[1][3],value[1][4],value[1][5],value[1][6],value[2]))
            fh_out2.write('%s.%s.%s.%s\n' % (genome,value[1][2],value[1][3],value[1][4]))
            fh_out3.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (value[1][0],value[1][1],value[1][2],value[1][3],value[1][4],value[1][5],value[1][6]))
        
    else:
        fh_out1.write('Name\tp-val\tChr\tStart\tEnd\tStrand\tLib\n')
        anum = 1
        for value in main_dict.values():
            # print(value)
            #print('Phas-%s\t%s\t%s\t%s\t%s\t%s\n' % (anum,value[1][1],value[1][2],value[1][3],value[1][4],value[1][6]))
            fh_out1.write('Phas-%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (anum,value[1][1],value[1][2],value[1][3],value[1][4],value[1][6],value[2]))
            fh_out2.write('%s.%s.%s.%s\n' % (genome,value[1][2],value[1][3],value[1][4]))
            fh_out3.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (value[1][0],value[1][1],value[1][2],value[1][3],value[1][4],value[1][5],value[1][6]))
            anum +=1
            
    fh_out1.close()
    fh_out2.close()
    fh_out3.close()
    return outfile1,outfile2,outfile3

def listConverter(resfolder,fileType):
    
    if fileType == 'L':
        print('\nList files selected for analysis - Converting them to readable format')
        fls = glob.glob(r'./%s/*.PARE.validation.list' % (res_folder))
        print ('\nHere are the files that will be converted:',fls,'\n')
        print ('Total files to analyze: %s' % (len(fls)))
        for fl in fls:
            fh_in = open(fl,'r')
            fh_out = open('%s_converted.list' % (fl.rpartition('.')[0]),'w')
            entries = fh_in.readlines()
            for i in entries:
                if i.strip(): ## Remove an empty line from end file
                    ent_splt = i.strip('\n').split('=')
                    #print(ent_splt[0].split('|'))
                    pval,phase,trash = ent_splt[0].split('|')
                    chromo_start,end = ent_splt[1].split('..')
                    chromo,start = chromo_start.split(':')
                    fh_out.write('%s\t%s\t%s\t%s\t%s\tNONE\tNONE\n' % (phase,pval,chromo.strip().replace('chr',''),start,end))##Chromosome has space before it which later gives error while key matching
            fh_in.close()
            fh_out.close()
        
    if fileType == 'C':
        print('\nList files selected for analysis - Converting them to readable format')
        fls = glob.glob(r'./%s/*csv' % (res_folder))
        print ('\nHere are the files that will be converted:',fls,'\n')
        print ('Total files to analyze: %s' % (len(fls)))
        for fl in fls:
            fh_in = open(fl,'r')
            header = fh_in.readline()
            fh_out = open('%s_converted.list' % (fl),'w')
            entries = fh_in.readlines()
            for i in entries:
                if i.strip(): ## Remove an empty line from end file
                    ent_splt = i.strip('\n').split('\t')
                    #print(ent_splt[0].split('|'))
                    name,pval,chromo,start,end,strand,Lib = i.strip('\n').split('\t')
                    fh_out.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\n' % (name,pval,chromo,start,end,strand,Lib))##Chromosome has space before it which later gives error while key matching
            fh_in.close()
            fh_out.close()
    else:
        pass
    
    return None

def main():
    if region == 'G':
        global overlapCutoff
        overlapCutoff = 0.50 ## = 0.25 for genomic and 0.50 for ncRNAs
    else:
        global overlapCutoff
        overlapCutoff = 0.25 ## = 0.25 for genomic and 0.50 for ncRNAs

    if fileType == 'L':
        listConverter(res_folder,fileType)
        main_dict = RemoveRedundant(res_folder,p_val,fileType)
    elif fileType == 'C':
        listConverter(res_folder,fileType)
        main_dict = compare(res_folder,fileType)
    else:
        main_dict = RemoveRedundant(res_folder,p_val,fileType)
    
    outfile1,outfile2,outfile3 = writer(main_dict)

if __name__ == '__main__':
    start = time.time()
    main()
    print ('It took', round(time.time()-start,2), 'sec')
    print ('\nCheers script finished sucessfully\n')
    sys.exit()

##v01 -> v03
##Added functionality to compare between similar loci and select the longest one

##v03 -> v04 (Critical bug fixed)
## Corrected bug with 'key' - Range was being made one integer less as last integer is never counted and with every run (file) there is change in key (one integer less) it is
###Therefore key from first run not matched woth earlier and all loci being retained

###v04-> v05 (Critical bug fixed)
#####Bug with main key remade fixed

###V05 -> v06
### 1. If a lower cutoff is used than only entries pertaining to that cutoff should be analyzed, as phas are redundant between different cutoffs
###Problem observed was that 'Key not found' and reason for that is because Key has already been removed during first instance and later
###Instances of same loci but lower cutoff find main key missing from main dictionary thats why error.
###Only entries for input cutoff will be analyzed
### 2. capture loci that are different in two given files

###v06 -> V07
###Pingchuan format added to compare files from different tissues
###Added library name in log file
###Added new files for each librray with clusters added - good to identify unique clusters i.e PARE validated and non-valiadted

###V08 -> v09 (Feb 2014)
##Added functionality to work on three file types and distinguish on the basis of switch - Working OK

### v09 -> v10 - Critical speed bug fixed
### The bug was related to appending chr to the start and end abd comparing the range. In cases when there is change in number of digits between start and end. The range for matching was generated incorrectly long and leads to freezing of script.
## In this version chromosome is not appended to start and end instead a check is doen for same chromosme and than range is generated, folllowed bu comparing ranges for overlap
## REgression - In this version I was getting error related to key-not found which is kind of historical error. Maybe in past (v04 -> v05) it was addressed by adding 1 to the end co-ordinates as while opening a range last number is not counted
## So after remaking the mainkey the last number as absent is not included in the key or something like that - For future 'Key not found' errors please check this first that

##Added p-val in name

##v1.0 -> v1.01
## Introduced functionality to combine results from csv files - this will help comparing old files with new files to identify new phased loci that needs manual curation
## Removed header as output of list converter as it's not generated always

##v1.0 -> v1.02
## Added overLap ratio for different regions in main()
## Removed chr_id as integer type as ncRNA names are not integers
## Modified main_key remade with additional replace of replace("'","") to make it functional for string chromosome/transcript IDs

## v1.03 -> 1.03
## Added a temp folder to write all "Uniq" files not working directory is not filled up with all less used files